---
date updated: '2021-05-29T16:03:31+05:30'

---

- # How to Learn About Data Collect and Wrangling(Cleaning)
  - (Estimated time: 2 months)

  - ==A significant part of data science work is centred around finding apt data that can help you solve your problem==

  - You can collect data from different legitimate sources -- scraping ( if the websites allows), APIs, databases, and publicly available repositories. D

  - Once you data in hand, an analyst will often find themselves cleaning data frames, working with multi-dimensional arrays, using descriptive/scientific computations, and manipulating data frames to aggregate data.

  - Data are rarely clean and formatted for use in the "real world". [[Pandas]] and [[NumPy]] are the two libraries that are at your disposal to go from dirty data to ready-to-analyze data

  - As you start feeing comfortable writing Python programs, feel free to start taking lesson on using libraries like pandas and numpy
- ### Resources to learn about data collection and cleaning
  - [freeCodeCamp course on learning NumPy, Pandas, matplotlib, and seaborn](https://www.youtube.com/watch?v=r-uOLxNrNk8))[[YouTube]]. ^d69558
  - Practical tutorial on [data manipulation with NumPy and Pandas in Python](https://www.hackerearth.com/practice/machine-learning/data-manipulation-visualisation-r-python/tutorial-data-manipulation-numpy-pandas-python/tutorial/) from HackerEarth.
  - [Kaggle Pandas tutorial](https://www.kaggle.com/learn/pandas)[free] -- A short and concise hands-on-tutorial that will walk you through commonly used data manipulations skills.[[Kaggle]]
  - [[Kaggle]]: [Data Cleaning course by Kaggle](https://www.kaggle.com/learn/data-cleaning)
  - [Coursera course on Introduction to Data Science in Python](https://www.coursera.org/learn/python-data-analysis?specialization=data-science-python) -- This is the first course in the [Applied Data science with Python Specializtion. ](https://www.coursera.org/specializations/data-science-python)[[Specialization]]
- ### Data collection project Ideas:
  -  [ ] Collect data form a website/API (open for public consumption) of your choice, and transform the data to store it from different sources into an aggregated file or table (DB). Example APIs include [TMDB](https://developers.themoviedb.org/3), [quandl](https://www.quandl.com/tools/python), [Twitter API](https://developer.twitter.com/en/docs), and so on.
  -  [ ] Pick any [publicly available dataset](https://towardsdatascience.com/data-repositories-for-almost-every-type-of-data-science-project-7aa2f98128b) and define a set of questions that you'd want to pursue after looking at the dataset and the domain. Wrangle the data to find out answers to those questions using Pandas and NumPy
